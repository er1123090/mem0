llm:
  provider: ollama
  config:
    model: 'llama2'
    temperature: 0.5
    top_p: 1
    stream: true
    base_url: http://localhost:11434

embedder:
  provider: huggingface
  config:
    model: 'BAAI/bge-small-en-v1.5'
